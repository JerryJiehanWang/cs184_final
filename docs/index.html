<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Project</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>

<body>
  <h1 align="middle">CS 184 Final Report: Volumetric Scattering Rendering</h1>
<h2 align="middle">Team Member: Jiehan Wang, Jiayue Tao, Yun Xu</h2>

<h2 align="middle">Abstract</h2>
<p>Our project implemented Volumetric Path Tracing. Volumetric Path Tracing is a technique that can show the effect of
  fog when light travels through media in the air.Currently, in project 3, we implement a path tracer which only
  support lights falling on explicit surface. We extended the path tracer in project 3 so that the light not only interacts
  with primitives' surface, but also in the air.
</p>

<h2 align="middle">Technical Approach</h2>
<h3>General techniques</h3>
  <div align="middle">
    <table style="width=100%"> 
      <tr>
        <td>
          <img src="./imgs/8.png" align="middle" width="800px"/>
          <figcaption align="middle">Volumetric scattering</figcaption>
        </td>
      </tr>
    </table>
  </div>
<p> Based on the skeleton of project, we implement the light interacting with the media by Random Walk. In this part, we
  modify the estimate_global_illumination and at_least_one_bounce function to support our implementions.
  First, before the
light first interacts with a surface, we randomly sample a distance, \(s\), using the PDF \(p_{medium} = ke^{-ks}\). Then,
we compare \(s\) with the distance between camera and the first hit point of the ray \(d\). If \(s < d\), we perform a
integration based on this equation: \(L_s(y, \Theta) = \int_{\Omega}\frac{\delta}{k}f(y, \Theta, \Theta')L(y, \Theta')d\omega'\),
  where \(\delta\) is the scattering coefficient between 0 and 1, describing how much percent of light are being scattered and \(k\)
  is the extinction coefficient between 0 and 1, describing how much percent of light are fell out during one interacting with the media.
  Additionally, \(f(y, \Theta, \Theta')\) is the phase function, which is similar to the BSDF in normal path tracing, describing
  the distribution of the bouncing light. I will talk about phase function later.
  If \(s \ge d\), we perform a normal path tracing. Notice that for global illumination, this step only affects the first bounce,
  all other bounces are normal path tracing. In sum, our approach can be concluded by this equation \(L(x, \Theta) = \int_{0}^{\infty}
  [s < d ? L_s(x-s\Theta, \Theta) : L_o(x - d\Theta, \Theta)]ke^{-ks}ds\). Notice that whether we take the normal path tracing or not,
  we always times the \(ke^{-ks}\) term, and also because the probability of whether we interact with the media or not are determined
  by this equation \(ke^{-ks}\), when we do monte carlo integration, these two terms cancel with each other.
</p>
  <p>Sampling from the light is similar but different for interacting with the media in the air. Based on the original function
    estimate_direct_lighting_importance, we modify it so that it support interacting with the media. Instead of the normal
    importance over light, which times the BSDF of the surface, a cosine term and divided by the pdf, the volumetric version
  times the irradiance with Phase function, scattering coefficient and divided by the extinction coefficient and pdf.
  We also times a filter Spectrum to implement fogs of different color.</p>

  <h3>Phase function</h3>
  <div align="middle">
    <table style="width=100%"> 
      <tr>
        <td>
          <img src="./imgs/7.png" align="middle" width="800px"/>
          <figcaption align="middle">Henyey-Greenstein phase function</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <p>Phase function is important in volumetric path tracing. We use phase function to sample the bouncing ray in global illumination.
  Na√Øvely, the simplest phase function is a uniform sphere sampling, where \(p(\Theta) = \frac{1}{4\pi}\). We also implement the
    Henyey-Greenstein phase function, which is \(p(\Theta) = \frac{1}{4\pi}\frac{1 - G^2}{(1 + G^2 - 2G\cos{\Theta})^{\frac{3}{2}}}\),
  where \(G\) is a constant between -1 and 1. If \(G = 0\), obviously it's a uniform sphere phase function. If \(G < 0\),
  higher probability that bouncing ray will towards the opposite direction of camera, and if \(G > 0\), higher probability that bouncing ray
  will towards the camera.</p>

  <h3>Problems we met</h3>
  <p>During our implementation of estimation of the radiance of particles in a media with direct illumination & importance sampling, we encountered a couple of difficulties. Because we modelled our implementation based on the importance sampling at surface hitpoints in project 3-1, the first problem that we encountered was that we did not remove the lambertian cosine term when estimating irradiance. We forgot that the atmosphere does not use the cosine term to evaluate falloff; instead, we need to multiply by a coefficient (scattering coefficient / extinction coefficient) to account for "fall off" due to out-scattering. Another issue that we encountered was re-writing raytrace_pixel() to weight each sample by its probability distribution based on the exponential decay of ray marching. Originally in proj3, this was not considered because every ray hits the same surface hitpoint with 100% probability. For volumetric rendering, however, we need to bias each sample because different camera rays from the same pixel land on different positions in the scene based on the medium. After realizing this, we modified our code to make sure the overall estimation is unbiased.</p>


  <h2 align="middle">Results</h2>
  <h3 align="middle">Rendering of different scenes</h2>
  <div align="middle">
    <table style="width=100%"> 
      <tr>
        <td>
          <img src="./imgs/1.png" align="middle" width="400px"/>
          <figcaption align="middle">CBspheres_lambertian with original path tracer</figcaption>
        </td>
        <td>
          <img src="./imgs/2.png" align="middle" width="400px"/>
          <figcaption align="middle">CBspheres_lambertian with participation of media</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="./imgs/3.png" align="middle" width="400px"/>
          <figcaption align="middle">spheres with original path tracer under spot lights</figcaption>
        </td>
        <td>
          <img src="./imgs/4.png" align="middle" width="400px"/>
          <figcaption align="middle">spheres with participation of media under spot lights</figcaption>
        </td>
      </tr>
      <br>
      </tr> 
        <td>
          <img src="./imgs/5.png" align="middle" width="400px"/>
          <figcaption align="middle">CBdragon with original path tracer under spot lights</figcaption>
        </td>
        <td>
          <img src="./imgs/6.png" align="middle" width="400px"/>
          <figcaption align="middle">CBdragon with participation of media under spot lights</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <p>Above are some scenes rendered. We can see that with participation of media, the whole scene gets blurred and contour of objects is less clear. We can also see two clear light beam in the air with participation of media under spot light.</p>
  <h3 align="middle">Comparison of different coefficients</h3>
  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="./report/4.png" align="middle" width="800px"/>
          <figcaption align="middle">different extinction coefficient</figcaption>        
        </td>
      </tr>
      <br>
      <tr> 
        <td>
          <img src="./report/5.png" align="middle" width="800px"/>
          <figcaption align="middle">different scattering coefficient</figcaption>        
        </td> 
      </tr> 
      <br>
      <tr>
        <td>
          <img src="./report/6.png" align="middle" width="800px"/>
          <figcaption align="middle">different G of HG phase function</figcaption>        
        </td> 
      </tr>         
    </table>
  </div>
  <p>As extinction coefficient increasing, the scene is getting darker; as scattering coefficient increasing, the scene is getting brighter; As G changing from positive to negative, the light is scattered from forward to backward.</p>


<h2 align="middle">Reference</h2>
<a href="http://luthuli.cs.uiuc.edu/~daf/courses/rendering/papers/lafortune96rendering.pdf">http://luthuli.cs.uiuc.edu/~daf/courses/rendering/papers/lafortune96rendering.pdf</a>
<a href="https://cs.dartmouth.edu/~wjarosz/publications/dissertation/chapter4.pdf">https://cs.dartmouth.edu/~wjarosz/publications/dissertation/chapter4.pdf</a>
<h2 align="middle">Contributions</h2>
<p>All team members actively attended meetings to decide the project topic, understand technical approaches in papers, discuss the implementation, and debugging the code.</p>
<p>Jiayue wrote most of the codes for importance direct lighting with media, and spot light sampling. She also created new dae files with Blender for rendering; made videos for milestone and final report; made slides for presentation; wrote part of write-up for milestone and final report; and rendered scenes for final results.</p>
<p>Jiehan wrote codes for global illumination with media, uniform sphere phase function, and HG phase function. He also made slides for presentation; wrote part of write-up for milestone and final report; and rendered scenes for final results.</p>
<p>Yun created new dae files with Blender for rendering, wrote part of write-up for milestone and final report, made slides for presentation, and rendered scenes for final results.</p>

</body>
</html>